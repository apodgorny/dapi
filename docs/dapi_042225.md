# DAPI: Dynamic API

## Overview

DAPI (Dynamic API) is an advanced execution framework for creating and composing dynamic, asynchronous operators in Python. It provides a flexible, modular architecture for defining, composing, and executing operations across different interpreters, with first-class support for both synchronous and asynchronous operations.

## Core Architecture

DAPI is built around several key concepts:

- **Operators**: Self-contained units of functionality with clearly defined inputs and outputs
- **Processes**: Compositions of operators that solve specific tasks
- **Interpreters**: Runtime environments that execute operator code
- **Services**: System components that manage operators, types, and execution

### Execution Model

```
┌────────────┐
│  Process   │
└─────┬──────┘
      │ invokes
      ▼
┌────────────┐     ┌────────────┐
│  Operator  │────▶│  Operator  │
└─────┬──────┘     └─────┬──────┘
      │                  │
      ▼                  ▼
┌────────────┐     ┌────────────┐
│Interpreter │     │Interpreter │
└────────────┘     └────────────┘
```

DAPI uses an asynchronous execution model, allowing operators to efficiently handle I/O-bound operations without blocking. This is particularly valuable when integrating with external services or performing network operations.

## Key Components

### Operators

Operators are the fundamental building blocks of DAPI. Each operator:

- Has a well-defined input and output schema (using Pydantic models)
- Can be implemented in Python or defined for interpretation by an LLM
- Supports asynchronous execution via `async/await`
- Can invoke other operators, enabling composition

Example of a Python operator:

```python
class Square(Operator):
    class InputType(Datum.Pydantic):
        x: float

    class OutputType(Datum.Pydantic):
        x: float

    async def invoke(self, input):
        x = input['x']
        return { 'x': x * x }
```

Example of an LLM operator:

```python
class AddOne(Operator):
    class InputType(Datum.Pydantic):
        x: float

    class OutputType(Datum.Pydantic):
        x: float

    code = '''
        'Given a number {{input.x}}, return its increment by one as { "x": input.x + 1 }'
    '''

    interpreter = 'llm'
    config = {
        'model_id': 'ollama::gemma3:4b',
        'temperature': 0
    }
```

### Processes

Processes are entry points that compose multiple operators to accomplish a specific task. A process:

- Defines a main operator as an entry point
- Orchestrates the flow of data between operators
- Handles input validation and output formatting

Example:

```python
class Process:
    entry = double_then_square  # Set the entry point to the double_then_square operator
```

### Interpreters

Interpreters are responsible for executing operator code in specific environments. DAPI includes:

- **PythonInterpreter**: Executes Python code using MiniPython (a restricted Python interpreter)
- **LLMInterpreter**: Sends prompts to language models and processes their responses
- **PluginInterpreter**: Loads and executes external Python modules that implement the Operator interface

### Services

Services manage the system's resources and operations:

- **OperatorService**: Manages operator registration, invocation, and execution
- **TypeService**: Handles data type definitions and validation
- **InstanceService**: Manages execution instances and their state
- **InterpreterService**: Coordinates interpreters for operator execution

## Data Flow

1. Process receives input data
2. Input is validated against the defined input schema
3. Process invokes its entry operator
4. Operators can invoke other operators, creating a call chain
5. Each operator's output is validated against its output schema
6. Results propagate back through the call chain
7. Process returns the final result

## Technical Implementation

### Operator Types

#### Python Operators vs Plugin Operators

DAPI supports two main types of operator implementations that work in different ways:

1. **Python Operators**:
   - Defined directly within process files
   - Registered via the API when the process is compiled
   - Executed by the Python interpreter using MiniPython
   - Code is extracted and sent to the server for execution
   - **Only the `async invoke(input)` method is used** - no other methods are imported or executed
   - Takes a single parameter (input dict) and returns a dict
   - Example:
     ```python
     class square(Operator):
         async def invoke(self, input):
             x = input['x']
             return { 'x': x * x }
     ```

2. **Plugin Operators**:
   - Defined in dedicated Python files in the `operators/` directory
   - Class name must follow PascalCase convention and match operator name in snake_case
     (e.g., `TimesTwo` class in `times_two.py` becomes the `times_two` operator)
   - Loaded and executed by the Plugin interpreter
   - Must inherit from the Operator base class
   - Typically uses `@classmethod` and includes a config parameter
   - Example:
     ```python
     # File: operators/times_two.py
     class TimesTwo(Operator):
         @classmethod
         async def invoke(cls, input_data, config=None):
             return {'x': input_data['x'] * 2}
     ```

When operators are called from Python code within processes, the class names are converted to snake_case function calls. For example:

```python
# Defined as a class
class DoubleSquare(Operator):
    async def invoke(self, input):
        # Called as function in snake_case: double_square
        return await double_square({'x': input['x'] * 2})
```

The key difference is that Python operators are serialized and sent to the server, while plugin operators are loaded directly from the filesystem. This makes plugin operators more suitable for complex operations that may require additional imports or specialized logic.

### Client System

DAPI uses a client-server architecture to manage operators and execute processes:

1. **Client**: Located in `dapi/lib/client.py`
   - Handles communication with the DAPI server
   - Provides methods for creating types and operators
   - Manages operator invocation and result retrieval
   - Handles compilation of process files

2. **Process Runner**: Located in `dapi/process.py`
   - Parses command-line arguments
   - Loads and compiles process files
   - Extracts input parameters from command-line arguments
   - Invokes the entry operator and displays results

The process flow works as follows:

1. The user runs a process with `python dapi/process.py processes/some_process.py --arg value`
2. The process runner loads the process file and extracts operator definitions
3. The client registers all operators and types with the server
4. The runner identifies the entry operator and constructs the input dictionary
5. The client invokes the entry operator with the input data
6. The server executes the operator and any operators it calls
7. The result is returned to the client and displayed to the user

This architecture allows DAPI to maintain a clean separation between definition and execution, with operators registered through the API but executed by the server.

### MiniPython

DAPI includes a custom Python interpreter called MiniPython that provides:

- Sandboxed execution of Python code
- Support for `async/await` syntax
- Capability to call external operators
- Controlled access to Python built-ins

### Async Support

DAPI fully embraces asynchronous programming:

- All operators use `async def invoke` method signatures
- Operator calls are awaited: `result = await call(params)`
- External API calls can be made non-blocking
- Error handling preserves the async call stack

### Datum: The Symmetrical Data Interface

At the core of DAPI's data handling is the `Datum` class, which provides a symmetrical interface for working with structured data:

#### Key Features

1. **Format Agnostic**: Datum provides a unified interface for working with different data formats:
   ```python
   # Convert between formats seamlessly
   datum.to_dict()    # Convert to Python dictionary
   datum.from_dict()  # Load from Python dictionary
   datum.to_json()    # Serialize to JSON string
   datum.from_json()  # Load from JSON string
   datum.to_yaml()    # Serialize to YAML string
   datum.from_yaml()  # Load from YAML string
   ```

2. **Symmetrical API Design**: Every conversion method has both a "to" and "from" counterpart, making data manipulation intuitive and predictable.

3. **Schema-Based Validation**: Datum wraps Pydantic models to provide robust validation:
   ```python
   # Define a schema using Pydantic
   class InputType(Datum.Pydantic):
       x: float
       
   # Validate data against the schema
   datum = Datum(InputType)
   datum.validate({'x': 2.0})  # Valid
   datum.validate({'x': 'abc'})  # Error: expected float, got str
   ```

4. **Path-Based Access**: Access nested data using dot notation:
   ```python
   # Access nested fields
   value = datum['user.profile.email']
   
   # Set nested fields
   datum['user.settings.theme'] = 'dark'
   ```

5. **Schema Conversion**: Convert between JSON schema and Pydantic models:
   ```python
   # Convert JSON schema to Pydantic model
   model = Datum.jsonschema_to_basemodel(schema_dict)
   
   # Get JSON schema from Pydantic model
   schema = datum.to_dict(schema=True)
   ```

#### Symmetrical Interface

The Datum class is designed with symmetry in mind, providing consistent methods for data manipulation:

| Direction | Dictionary | JSON | YAML | Empty Template |
|-----------|------------|------|------|---------------|
| **To**    | to_dict()  | to_json() | to_yaml() | to_empty_dict() |
| **From**  | from_dict() | from_json() | from_yaml() | to_empty_datum() |

This symmetrical design makes it intuitive to work with data in different formats, with consistent method naming and behavior across all conversions.

### Input/Output Validation

DAPI uses Datum and Pydantic for robust data validation:

- Input and output schemas are defined as Pydantic models
- Datum provides a wrapper around these models with additional functionality
- Automatic validation of inputs before operator execution
- Automatic validation of outputs after operator execution
- Clear error messages when validation fails, with detailed information about what went wrong

### Database Structure

DAPI uses a SQL database to store operators and execution instances. The main tables are:

#### Operators Table

The `operators` table stores all registered operators:

```python
class OperatorRecord(Record):
    __tablename__ = 'operators'

    name         : Mapped[str]             = mapped_column(String(255), primary_key=True, comment='Unique operator name')
    description  : Mapped[str]             = mapped_column(Text, nullable=True, comment='Optional operator description')
    code         : Mapped[str]             = mapped_column(Text, nullable=True, comment='Source code or prompt (or empty for composite)')
    interpreter  : Mapped[str]             = mapped_column(String(50), nullable=False, comment='Interpreter name (e.g. python, llm, composite)')
    
    input_type   : Mapped[Dict[str, Any]]  = mapped_column(JSON, nullable=False, comment='Full JSON Schema')
    output_type  : Mapped[Dict[str, Any]]  = mapped_column(JSON, nullable=False, comment='Full JSON Schema')

    scope        : Mapped[Dict[str, Any]]  = mapped_column(MutableDict.as_mutable(JSON), default=dict, comment='Runtime scope for function operators')
    config       : Mapped[Dict[str, Any]]  = mapped_column(MutableDict.as_mutable(JSON), default=dict, comment='Configuration passed to interpreter')
```

Key fields:
- `name`: Unique identifier for the operator
- `code`: Source code (Python) or prompt (LLM)
- `interpreter`: The type of interpreter to use (python, llm, etc.)
- `input_type` and `output_type`: JSON schemas defining data structure

#### Runtime Instances Table

The `runtime` table stores execution instances:

```python
class OperatorInstanceRecord(Record):
    __tablename__ = 'runtime'

    id          = Column(String(36), primary_key=True, default=lambda: str(uuid.uuid4()), comment='Instance ID')
    name        = Column(String, nullable=True, comment='Optional instance name (used in composite scope)')
    operator    = Column(String, nullable=False, comment='Operator name this instance runs')

    input       = Column(JSON, nullable=False, comment='Input data for operator')
    output      = Column(JSON, default=dict, comment='Result of execution')

    status      = Column(Enum(OperatorInstanceStatus), nullable=False, default=OperatorInstanceStatus.created, comment='Execution status')
    error       = Column(Text, nullable=True, comment='Error message if any')

    children    = Column(JSON, default=list, comment='IDs of child operator instances')

    created_at  = Column(DateTime, default=datetime.utcnow, comment='Creation timestamp')
    invoked_at  = Column(DateTime, nullable=True, comment='Time of successful invocation')
```

Key fields:
- `id`: Unique identifier for the execution instance
- `operator`: The operator being executed
- `input` and `output`: The data passed to and returned from the operator
- `status`: Current execution state (created, running, invoked, error)
- `children`: References to child operator instances (for composite operators)

This database structure allows DAPI to:
1. Store operator definitions persistently
2. Track execution instances and their states
3. Capture input and output data for debugging
4. Record execution history for auditing and monitoring

## Error Handling

DAPI provides a comprehensive error handling system:

- Detailed error messages that trace through the operator call stack
- Validation errors that clearly identify the problematic fields
- Runtime errors that pinpoint execution issues
- HTTP error responses for the API layer

## API Interface

DAPI exposes a REST API for:

- Creating and registering operators
- Defining data types
- Invoking operators with input data
- Retrieving execution results

## Command Line Interface

The CLI allows running process scripts:

```bash
python dapi/process.py processes/all.py --x 2
```

This will:
1. Load the process defined in `processes/all.py`
2. Register all operators defined in the process
3. Invoke the entry operator with the provided argument (`x=2`)
4. Return and display the result

## Advanced Features

### Recursive Operation

DAPI supports recursive operator calls, allowing for:

- Tree-like data processing
- Depth-limited recursion
- Branching execution paths

Example:

```python
class BranchRecursion(Operator):
    '''Recursively calls another operator and branches by returned list items.'''

    async def invoke(cls, input_data, config=None):
        if level < depth:
            for item in result[list_field]:
                child = await cls.invoke({
                    'depth'     : depth,
                    'level'     : level + 1,
                    'operator'  : operator,
                    'get_input' : get_input,
                    'input_data': next_input
                })
```

### LLM Integration

DAPI seamlessly integrates with Language Models:

- Define operators using natural language prompts
- Process text inputs and outputs
- Chain LLM calls with traditional code
- Configure model parameters (temperature, tokens, etc.)

## Best Practices

### Process Design

1. **Single Responsibility**: Each operator should do one thing well
2. **Clear Interfaces**: Define precise input and output schemas
3. **Error Handling**: Propagate and transform errors appropriately
4. **Composition**: Build complex processes from simple operators
5. **Statelessness**: Operators should be stateless when possible

### Data Handling

1. Use dictionary access (`input['field']`) instead of attribute access 
2. Always validate data against schemas
3. Handle missing or null values explicitly
4. Use appropriate data types for each field
5. Keep data structures flat when possible

### Performance Optimization

1. Leverage asynchronous programming for I/O-bound operations
2. Cache expensive computation results
3. Batch API calls when possible
4. Use appropriate chunking for large data

## Example Use Cases

1. **Data Processing Pipelines**: Chain operators to transform, validate, and enrich data
2. **AI Workflows**: Combine traditional code with LLM capabilities
3. **API Orchestration**: Call and coordinate multiple external services
4. **Recursive Data Processing**: Process hierarchical data with controlled recursion
5. **Interactive System Building**: Create complex interactive systems by combining operators

## Conclusion

DAPI provides a powerful, flexible framework for building dynamic, asynchronous systems in Python. Its modular architecture, strong typing, and support for different execution environments make it suitable for a wide range of applications.

By separating execution from implementation and providing first-class async support, DAPI enables developers to create complex, performant systems with clear, maintainable code.
